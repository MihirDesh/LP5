{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fcd6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = r\"\"\"\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <limits.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <chrono>\n",
    "\n",
    "#define BLOCK_SIZE 256\n",
    "\n",
    "__global__ void reduceMin(int* input, int* output, int size) {\n",
    "    __shared__ int sdata[BLOCK_SIZE];\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    sdata[tid] = (i < size) ? input[i] : INT_MAX;\n",
    "    __syncthreads();\n",
    "\n",
    "    for (unsigned int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
    "        if (tid < stride) {\n",
    "            sdata[tid] = min(sdata[tid], sdata[tid + stride]);\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (tid == 0) output[blockIdx.x] = sdata[0];\n",
    "}\n",
    "\n",
    "__global__ void reduceMax(int* input, int* output, int size) {\n",
    "    __shared__ int sdata[BLOCK_SIZE];\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    sdata[tid] = (i < size) ? input[i] : INT_MIN;\n",
    "    __syncthreads();\n",
    "\n",
    "    for (unsigned int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
    "        if (tid < stride) {\n",
    "            sdata[tid] = max(sdata[tid], sdata[tid + stride]);\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (tid == 0) output[blockIdx.x] = sdata[0];\n",
    "}\n",
    "\n",
    "__global__ void reduceSum(int* input, int* output, int size) {\n",
    "    __shared__ int sdata[BLOCK_SIZE];\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    sdata[tid] = (i < size) ? input[i] : 0;\n",
    "    __syncthreads();\n",
    "\n",
    "    for (unsigned int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
    "        if (tid < stride) {\n",
    "            sdata[tid] += sdata[tid + stride];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (tid == 0) output[blockIdx.x] = sdata[0];\n",
    "}\n",
    "\n",
    "inline cudaError_t checkCudaError(cudaError_t err, const char* msg) {\n",
    "    if (err != cudaSuccess) {\n",
    "        printf(\"CUDA Error: %s - %s\\\\n\", msg, cudaGetErrorString(err));\n",
    "        exit(EXIT_FAILURE);\n",
    "    }\n",
    "    return err;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int size = 1 << 10;\n",
    "    int* h_input = (int*)malloc(size * sizeof(int));\n",
    "    for (int i = 0; i < size; i++) {\n",
    "        h_input[i] = rand() % 100 + 1;\n",
    "    }\n",
    "\n",
    "    int cpu_min = INT_MAX, cpu_max = INT_MIN, cpu_sum = 0;\n",
    "    auto start_cpu = std::chrono::high_resolution_clock::now();\n",
    "    for (int i = 0; i < size; i++) {\n",
    "        cpu_min = (h_input[i] < cpu_min) ? h_input[i] : cpu_min;\n",
    "        cpu_max = (h_input[i] > cpu_max) ? h_input[i] : cpu_max;\n",
    "        cpu_sum += h_input[i];\n",
    "    }\n",
    "    auto end_cpu = std::chrono::high_resolution_clock::now();\n",
    "    double cpu_time = std::chrono::duration<double, std::milli>(end_cpu - start_cpu).count();\n",
    "    float cpu_avg = (float)cpu_sum / size;\n",
    "\n",
    "    int *d_input, *d_output_min, *d_output_max, *d_output_sum;\n",
    "    int gridSize = (size + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "\n",
    "    checkCudaError(cudaMalloc((void**)&d_input, size * sizeof(int)), \"Malloc d_input\");\n",
    "    checkCudaError(cudaMalloc((void**)&d_output_min, gridSize * sizeof(int)), \"Malloc d_output_min\");\n",
    "    checkCudaError(cudaMalloc((void**)&d_output_max, gridSize * sizeof(int)), \"Malloc d_output_max\");\n",
    "    checkCudaError(cudaMalloc((void**)&d_output_sum, gridSize * sizeof(int)), \"Malloc d_output_sum\");\n",
    "\n",
    "    checkCudaError(cudaMemcpy(d_input, h_input, size * sizeof(int), cudaMemcpyHostToDevice), \"Memcpy input\");\n",
    "\n",
    "    cudaEvent_t start_gpu, stop_gpu;\n",
    "    cudaEventCreate(&start_gpu);\n",
    "    cudaEventCreate(&stop_gpu);\n",
    "    cudaEventRecord(start_gpu);\n",
    "\n",
    "    reduceMin<<<gridSize, BLOCK_SIZE>>>(d_input, d_output_min, size);\n",
    "    reduceMax<<<gridSize, BLOCK_SIZE>>>(d_input, d_output_max, size);\n",
    "    reduceSum<<<gridSize, BLOCK_SIZE>>>(d_input, d_output_sum, size);\n",
    "\n",
    "    checkCudaError(cudaGetLastError(), \"Kernel launch failed\");\n",
    "    cudaEventRecord(stop_gpu);\n",
    "    cudaEventSynchronize(stop_gpu);\n",
    "\n",
    "    float gpu_time = 0.0f;\n",
    "    cudaEventElapsedTime(&gpu_time, start_gpu, stop_gpu);\n",
    "\n",
    "    int* h_output_min = (int*)malloc(gridSize * sizeof(int));\n",
    "    int* h_output_max = (int*)malloc(gridSize * sizeof(int));\n",
    "    int* h_output_sum = (int*)malloc(gridSize * sizeof(int));\n",
    "\n",
    "    checkCudaError(cudaMemcpy(h_output_min, d_output_min, gridSize * sizeof(int), cudaMemcpyDeviceToHost), \"Memcpy min output\");\n",
    "    checkCudaError(cudaMemcpy(h_output_max, d_output_max, gridSize * sizeof(int), cudaMemcpyDeviceToHost), \"Memcpy max output\");\n",
    "    checkCudaError(cudaMemcpy(h_output_sum, d_output_sum, gridSize * sizeof(int), cudaMemcpyDeviceToHost), \"Memcpy sum output\");\n",
    "\n",
    "    int gpu_min = INT_MAX, gpu_max = INT_MIN, gpu_sum = 0;\n",
    "    for (int i = 0; i < gridSize; i++) {\n",
    "        gpu_min = (h_output_min[i] < gpu_min) ? h_output_min[i] : gpu_min;\n",
    "        gpu_max = (h_output_max[i] > gpu_max) ? h_output_max[i] : gpu_max;\n",
    "        gpu_sum += h_output_sum[i];\n",
    "    }\n",
    "    float gpu_avg = (float)gpu_sum / size;\n",
    "\n",
    "    printf(\"\\\\nCPU Results:\\\\n\");\n",
    "    printf(\"Min: %d | Max: %d | Sum: %d | Avg: %.2f | Time: %.2f ms\\\\n\", cpu_min, cpu_max, cpu_sum, cpu_avg, cpu_time);\n",
    "\n",
    "    printf(\"\\\\nGPU Results:\\\\n\");\n",
    "    printf(\"Min: %d | Max: %d | Sum: %d | Avg: %.2f | Time: %.2f ms\\\\n\", gpu_min, gpu_max, gpu_sum, gpu_avg, gpu_time);\n",
    "\n",
    "    free(h_input);\n",
    "    free(h_output_min);\n",
    "    free(h_output_max);\n",
    "    free(h_output_sum);\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output_min);\n",
    "    cudaFree(d_output_max);\n",
    "    cudaFree(d_output_sum);\n",
    "    cudaEventDestroy(start_gpu);\n",
    "    cudaEventDestroy(stop_gpu);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open(\"main.cu\", \"w\") as f:\n",
    "    f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31687892",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 main.cu -o main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3177cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./main"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
